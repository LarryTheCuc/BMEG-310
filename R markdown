---
title: "BMEG 310 Assignment 2 Q1"
author: "Project Group 16"
date: "2023-10-16"
output: pdf_document
---
```{r}

ovarian.dataset <- read.delim("ovarian.data", sep=",", header = FALSE)
features <- c("perimeter", "area", "smoothness", "symmetry", "concavity", paste("protein", seq(1, 25), sep=""))
names(ovarian.dataset) <- c("cell_id", "diagnosis", features) # paste0(features,"_mean"), paste0(features,"_se"), paste0(features,"_worst")
head(ovarian.dataset)

# Q1. Dimensionality Reduction

# Q1.1.

features_data <- ovarian.dataset[, features]
scaled_features <- scale(features_data)
pca_result <- prcomp(scaled_features)
summary(pca_result)

pc1_variance <- (pca_result$sdev[1]^2 / sum(pca_result$sdev^2)) * 100

cat("42.77% of variation is associated with PC1.")

# Q1.2.

# Calculate cumulative explained variance
cumulative_variance <- cumsum((pca_result$sdev^2) / sum(pca_result$sdev^2)) * 100

# Find the number of PCs needed to achieve 90% explained variance
PCs_needed <- which(cumulative_variance >= 90)[1]

cat("9 PCs are needed to achieve 90% representation of the variance.")

# Q1.3.

library(devtools)
library(ggbiplot)

ggbiplot(pca_result, choices=c(1,2), ellipse = TRUE, groups = ovarian.dataset$diagnosis)

# Q1.4.

library(ggplot2)

ggplot(ovarian.dataset, aes(x = area, y = concavity, color = diagnosis)) + geom_point()

# Q1.5.

cat("The primary difference between the two plots is that the first one is a principle component analysis (PCA) plot of the first two principle components of the dataset. The second plot is a direct comparison between the area and concavity features of the data. The PCA plot gives better separation between the classes as opposed to the area vs. concavity plot. This suggests that the two principal components capture a more significant portion of the variation that is relevant for distinguishing between benign and malignant cells.")

# Q1.6.

boxplot(pca_result$x, main = "Distribution of PCs", scale = TRUE, center = TRUE)

```
## Q2. Clustering 

## Function used to calcualte accuarcy, precission and recall

```{r definition}
CompareKLabels <- function(kLabels, TrueLabels){
  #test correspondence of labels 1 and 2 to M or B
  OneAsM <- ifelse(kLabels == 1, "M", kLabels)
  OneAsM <- ifelse(OneAsM == 2, "B", OneAsM)
  
  OneAsB <- ifelse(kLabels == "1", "B", kLabels)
  OneAsB <- ifelse(OneAsB == 2, "M", OneAsB)
  
  SuccessM <- sum(OneAsM == TrueLabels)
  SuccessB <- sum(OneAsB == TrueLabels)
  
  #compare which yields higher accuracy to the labels
  if (SuccessM > SuccessB){
    Accuracy <- SuccessM
    FoundLabels <-  OneAsM
  } else {
    Accuracy <- SuccessB
    FoundLabels <- OneAsB
  }
  
  #return how many matched the real labels
  percentAcc <-  Accuracy / length(kLabels)
  
  tp <- length(which(TrueLabels=="M"))
  tn <- length(which(TrueLabels=="B"))
  fp <- length(which(FoundLabels=="M"))
  fn <- length(which(TrueLabels=="B"))
  
  percision <- (tp) / (tp + fp)
  recall <- (tp) / (tp + fn)
  
  values <- data.frame(percentAcc, percision,recall)
  return(values)
}
```


## Question 2.1

```{r Q2.1}
##question 2 kmeans clustering
library(factoextra)

#create kmeans clusters 
ovarian.k <- kmeans(scaled_features, 2, iter.max = 10, nstart=1)
print(ovarian.k)

#visualize clusters
fviz_cluster(ovarian.k, ovarian.dataset[,3:32], ellipse.type = "norm")

#making a function that will take both kclusted labels and the true labels and 
#compare the accuracy
result1 <- CompareKLabels(ovarian.k$cluster,ovarian.dataset$diagnosis)
result1

```

## Question 2.2

```{r Q2.2}
#empty vector to store accuracy
accuracies <- numeric(10)

for(i in 1:10){
  tempKData <- kmeans(scaled_features, centers = 2, nstart = 1)
  valsDF <- CompareKLabels(tempKData$cluster, ovarian.dataset$diagnosis)
  accuracies[i] <- valsDF[1,1]
}

meanAcc <- mean(accuracies)
meanAcc

```

## Question 2.3

```{r Q2.3}
#empty vector to store accuracies
topPC <- pca_result$x[,1:5]

topPc_K <- kmeans(topPC,2)
PcaKvals <-CompareKLabels(topPc_K$cluster, ovarian.dataset$diagnosis)
PcaKvals
```

## Question 2.4

Comparing the accuracy, precision and recall of the two methods we see that our first method (kmeans on the data directly) provides a higher accuracy and precision


## Q.3 Classification
